{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Required imports",
   "id": "2e5f9121b01d8acd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import scikit_posthocs as sp\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import pingouin as pg\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "id": "9ab68bababcf3dd2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load results",
   "id": "4a59792fe921d924"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "methods = ['LBP', 'HOG', 'FN', 'CNN']\n",
    "metrics   = [\"FAR\", \"FRR\", \"Precision\", \"Recall\", \"Time\"]\n",
    "perturbations = [\n",
    "    \"original\", \"brightness_down\", \"brightness_up\", \"contrast_down\", \"contrast_up\",\n",
    "    \"saturation_down\", \"saturation_up\", \"rotate_15\", \"rotate_-15\", \"gaussian_blur\", \"color_shift\"\n",
    "]\n",
    "\n",
    "long_frames = []\n",
    "\n",
    "for m in methods:\n",
    "    g_path = f\"{m}_general_statistics.csv\"\n",
    "    df_g   = pd.read_csv(g_path)\n",
    "    df_g['Method']       = m\n",
    "    df_g['Perturbation'] = None        # no perturbation\n",
    "\n",
    "    df_g = df_g.rename(columns=str.capitalize)\n",
    "\n",
    "    df_g_long = df_g.melt(\n",
    "        id_vars=['Method', 'Perturbation'],\n",
    "        value_vars=metrics, # flattening by metrics\n",
    "        var_name='Metric',\n",
    "        value_name='Value'\n",
    "    )\n",
    "    long_frames.append(df_g_long)\n",
    "\n",
    "    p_path = f\"{m}_perturbation_statistics.csv\"\n",
    "    df_p   = pd.read_csv(p_path)\n",
    "    df_p['Method'] = m\n",
    "\n",
    "    df_p = df_p.rename(columns=str.capitalize)\n",
    "\n",
    "    df_p_long = df_p.melt(\n",
    "        id_vars=['Method', 'Perturbation'],   # columns already exists in file\n",
    "        value_vars=['far', 'frr', 'precision', 'recall'], # there is no \"Time\" for perturbations\n",
    "        var_name='Metric',\n",
    "        value_name='Value'\n",
    "    )\n",
    "    long_frames.append(df_p_long)\n",
    "\n",
    "all_results = pd.concat(long_frames, ignore_index=True)\n",
    "all_results.to_csv(\"all_results_long.csv\", index=False)"
   ],
   "id": "20aa94a2ce28ec30",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "methods = ['LBP', 'HOG', 'FN', 'CNN']\n",
    "metrics   = [\"FAR\", \"FRR\", \"Precision\", \"Recall\", \"Time\"]\n",
    "perturbations = [\n",
    "    \"original\", \"brightness_down\", \"brightness_up\", \"contrast_down\", \"contrast_up\",\n",
    "    \"saturation_down\", \"saturation_up\", \"rotate_15\", \"rotate_-15\", \"gaussian_blur\", \"color_shift\"\n",
    "]\n",
    "\n",
    "general_dfs = []\n",
    "for m in methods:\n",
    "    df = pd.read_csv(f\"{m}_general_statistics.csv\")\n",
    "    df[\"Method\"] = m\n",
    "    general_dfs.append(df)\n",
    "df_general_all = pd.concat(general_dfs)\n",
    "\n",
    "perturbation_dfs = []\n",
    "for m in methods:\n",
    "    df = pd.read_csv(f\"{m}_perturbation_statistics.csv\")\n",
    "    df[\"Method\"] = m\n",
    "    perturbation_dfs.append(df)\n",
    "df_perturb_all = pd.concat(perturbation_dfs)\n",
    "\n",
    "df_general_long = pd.melt(df_general_all, id_vars=[\"Method\"], value_vars=methods, var_name=\"Metric\", value_name=\"Value\")\n",
    "df_perturb_long = pd.melt(df_perturb_all, id_vars=[\"Method\", \"perturbation\"], value_vars=methods[:4], var_name=\"Metric\", value_name=\"Value\")"
   ],
   "id": "244d21061b4818e9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Statistical analysis",
   "id": "39298c0ffb1b81d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "alpha = 0.05",
   "id": "706ca45d780ccaf9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def run_general_tests(df):\n",
    "    results = []\n",
    "    for metric in metrics:\n",
    "        data = df[df[\"Metric\"] == metric]\n",
    "\n",
    "        # normality\n",
    "        pvals = [stats.shapiro(data[data[\"Method\"] == m][\"Value\"]).pvalue for m in methods]\n",
    "        normal = all(p > alpha for p in pvals)\n",
    "\n",
    "        # homogeneity of variance\n",
    "        grouped = [data[data[\"Method\"] == m][\"Value\"] for m in methods]\n",
    "        _, p_levene = stats.levene(*grouped)\n",
    "        equal_var = p_levene > alpha\n",
    "\n",
    "        if normal  and equal_var:\n",
    "            stat, p = stats.f_oneway(*(data[data[\"Method\"] == m][\"Value\"] for m in methods))\n",
    "            test_type = \"ANOVA\"\n",
    "            # post hoc Tukey\n",
    "            tukey = pairwise_tukeyhsd(data[\"Value\"], data[\"Method\"])\n",
    "            posthoc_df = pd.DataFrame(data=tukey._results_table.data[1:], columns=tukey._results_table.data[0])\n",
    "\n",
    "        elif normal and not equal_var:\n",
    "            model = ols(\"Value ~ Method\", data=data).fit()\n",
    "            anova_table = sm.stats.anova_lm(model, typ=2, robust=\"hc3\")\n",
    "            stat = anova_table[\"F\"][0]\n",
    "            p = anova_table[\"PR(>F)\"][0]\n",
    "            test_type = \"Welch ANOVA\"\n",
    "            # post hoc Games Howell\n",
    "            posthoc_df = pg.pairwise_gameshowell(dv=\"Value\", between=\"Method\", data=data)\n",
    "\n",
    "        else:\n",
    "            stat, p = stats.kruskal(*(data[data[\"Method\"] == m][\"Value\"] for m in methods))\n",
    "            test_type = \"Kruskal-Wallis\"\n",
    "            # post hoc Dunn\n",
    "            posthoc_df = sp.posthoc_dunn(data, val_col=\"Value\", group_col=\"Method\", p_adjust=\"bonferroni\")\n",
    "            posthoc_df.reset_index(inplace=True)\n",
    "\n",
    "        results.append({\n",
    "            \"Metric\": metric,\n",
    "            \"Test\": test_type,\n",
    "            \"Stat\": stat,\n",
    "            \"p-value\": p\n",
    "        })\n",
    "\n",
    "        posthoc_df.to_csv(f\"posthoc_general_{metric}.csv\", index=False)\n",
    "\n",
    "    pd.DataFrame(results).to_csv(\"general_test_results.csv\", index=False)\n",
    "    return results, posthoc_df"
   ],
   "id": "4f7c3f7a2c6f209c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def run_perturb_tests(df):\n",
    "    all_results = []\n",
    "    for perturb in perturbations:\n",
    "        for metric in metrics[:4]:  # without time\n",
    "            data = df[(df[\"perturbation\"] == perturb) & (df[\"Metric\"] == metric)]\n",
    "\n",
    "            pvals = [stats.shapiro(data[data[\"Method\"] == m][\"Value\"]).pvalue for m in methods]\n",
    "            normal = all(p > alpha for p in pvals)\n",
    "\n",
    "            # homogeneity of variance\n",
    "            method_groups = [data[data[\"Method\"] == m][\"Value\"] for m in methods]\n",
    "            p_levene = stats.levene(*method_groups).pvalue\n",
    "            equal_var = p_levene > alpha\n",
    "\n",
    "            if normal and equal_var:\n",
    "                stat, p = stats.f_oneway(*(data[data[\"Method\"] == m][\"Value\"] for m in methods))\n",
    "                test_type = \"ANOVA\"\n",
    "                tukey = pairwise_tukeyhsd(data[\"Value\"], data[\"Method\"])\n",
    "                posthoc_df = pd.DataFrame(data=tukey._results_table.data[1:], columns=tukey._results_table.data[0])\n",
    "            elif normal and not equal_var:\n",
    "                model = pg.welch_anova(dv=\"Value\", between=\"Method\", data=data)\n",
    "                stat = model[\"F\"].values[0]\n",
    "                p = model[\"p-unc\"].values[0]\n",
    "                test_type = \"Welch ANOVA\"\n",
    "                posthoc_df = pg.pairwise_gameshowell(dv=\"Value\", between=\"Method\", data=data)\n",
    "            else:\n",
    "                stat, p = stats.kruskal(*(data[data[\"Method\"] == m][\"Value\"] for m in methods))\n",
    "                test_type = \"Kruskal-Wallis\"\n",
    "                posthoc_df = sp.posthoc_dunn(data, val_col=\"Value\", group_col=\"Method\", p_adjust=\"bonferroni\")\n",
    "                posthoc_df.reset_index(inplace=True)\n",
    "\n",
    "            all_results.append({\n",
    "                \"Perturbation\": perturb,\n",
    "                \"Metric\": metric,\n",
    "                \"Test\": test_type,\n",
    "                \"Stat\": stat,\n",
    "                \"p-value\": p\n",
    "            })\n",
    "\n",
    "            posthoc_df.to_csv(f\"posthoc_{perturb}_{metric}.csv\", index=False)\n",
    "\n",
    "    pd.DataFrame(all_results).to_csv(\"perturbation_test_results.csv\", index=False)\n",
    "\n",
    "    return all_results, posthoc_df"
   ],
   "id": "1f304e77615309f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Results presentation",
   "id": "89788c2496bd775f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluation Metrics Summary",
   "id": "bf5ebadd080bb5b9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### General Metrics",
   "id": "ec15826312a78811"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for metric in metrics:\n",
    "    df_metric = df_general_all[[\"Method\", metric]].copy()\n",
    "    df_metric = df_metric.rename(columns={metric: \"Value\"})\n",
    "\n",
    "    summary = df_metric.groupby(\"Method\")[\"Value\"].agg(\n",
    "        mean=\"mean\",\n",
    "        std=\"std\",\n",
    "        min=\"min\",\n",
    "        q1=lambda x: x.quantile(0.25),\n",
    "        median=\"median\",\n",
    "        q3=lambda x: x.quantile(0.75),\n",
    "        max=\"max\"\n",
    "    ).round(4).reset_index()\n",
    "\n",
    "    print(f\"\\n Metric: {metric}\")\n",
    "    print(summary.to_string(index=False))"
   ],
   "id": "4603c960b429558a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Metrics for perturbations",
   "id": "5807cc425f0472f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for metric in metrics[:4]:\n",
    "    for pert in perturbations:\n",
    "        df_subset = df_perturb_all[df_perturb_all[\"perturbation\"] == pert]\n",
    "        df_metric = df_subset[[\"Method\", metric]].copy()\n",
    "        df_metric = df_metric.rename(columns={metric: \"Value\"})\n",
    "\n",
    "        summary = df_metric.groupby(\"Method\")[\"Value\"].agg(\n",
    "            mean=\"mean\",\n",
    "            std=\"std\",\n",
    "            min=\"min\",\n",
    "            q1=lambda x: x.quantile(0.25),\n",
    "            median=\"median\",\n",
    "            q3=lambda x: x.quantile(0.75),\n",
    "            max=\"max\"\n",
    "        ).round(4).reset_index()\n",
    "\n",
    "        print(f\"\\n Perturbation: {pert} | Metric: {metric}\")\n",
    "        print(summary.to_string(index=False))"
   ],
   "id": "74c1286d6a63965b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Statistical analysis (results)",
   "id": "f26ea01f727f80d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "res, posthocs = run_general_tests(df_general_long)\n",
    "print(10*\"-\", \"  RESULTS GENERAL \", 10*\"-\")\n",
    "print(res)\n",
    "print(10*\"-\", \" POST-HOC RESULTS \", 10*\"-\")\n",
    "print(posthocs)"
   ],
   "id": "bd55ef43153081e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "res_per, posthocs_per = run_perturb_tests(df_perturb_long)\n",
    "print(10*\"-\", \" RESULTS PERTURBATION \", 10*\"-\")\n",
    "print(res_per)\n",
    "print(10*\"-\", \"   POST-HOC RESULTS   \", 10*\"-\")\n",
    "print(posthocs_per)"
   ],
   "id": "5b99e7042861ce40"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visualization of Results",
   "id": "a654ced209afef4d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Histograms",
   "id": "f12ab0f852c1f9b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class_metrics = [\"FAR\", \"FRR\", \"Precision\", \"Recall\"]\n",
    "\n",
    "agg_class = (\n",
    "    df_general_long[df_general_long[\"Metric\"].isin(class_metrics)]\n",
    "    .groupby([\"Method\", \"Metric\"])[\"Value\"]\n",
    "    .agg(mean=\"mean\", std=\"std\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(\n",
    "    data=agg_class,\n",
    "    x=\"Method\",\n",
    "    y=\"mean\",\n",
    "    hue=\"Metric\",\n",
    "    palette=\"Set2\",\n",
    "    capsize=.15,\n",
    "    errcolor=\"black\",\n",
    "    errwidth=1,\n",
    ")\n",
    "for idx, row in agg_class.iterrows():\n",
    "    x_pos = list(methods).index(row[\"Method\"]) + (-0.3 + 0.2*class_metrics.index(row[\"Metric\"]))\n",
    "    plt.errorbar(x=x_pos, y=row[\"mean\"], yerr=row[\"std\"], fmt='none',\n",
    "                 ecolor='black', capsize=4, linewidth=1)\n",
    "\n",
    "plt.title(\"Model Metrics Comparison\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/bar_metrics.svg\", format=\"svg\")\n",
    "plt.show()"
   ],
   "id": "b70195c89a7f42e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "time_df = (\n",
    "    df_general_long[df_general_long[\"Metric\"] == \"Time\"]\n",
    "    .groupby(\"Method\")[\"Value\"]\n",
    "    .agg(mean=\"mean\", std=\"std\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(\n",
    "    data=time_df, x=\"Method\", y=\"mean\",\n",
    "    color=\"lightsteelblue\", capsize=.2, errcolor=\"black\", errwidth=1\n",
    ")\n",
    "plt.errorbar(x=range(len(time_df)), y=time_df[\"mean\"], yerr=time_df[\"std\"],\n",
    "             fmt='none', ecolor='black', capsize=4, linewidth=1)\n",
    "plt.title(\"Time of extraction\")\n",
    "plt.ylabel(\"Time [s]\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/time.svg\", format=\"svg\")\n",
    "plt.show()"
   ],
   "id": "ff2ebb6cf52dd94"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Heatmaps",
   "id": "c71a360b98c84ed4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for metric in metrics:\n",
    "    pivot = (\n",
    "        df_perturb_long[df_perturb_long[\"Metric\"].str.lower() == metric.lower()]\n",
    "        .pivot_table(index=\"perturbation\", columns=\"Method\", values=\"Value\", aggfunc=\"mean\")\n",
    "        .reindex(index=perturbations)\n",
    "    )\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.heatmap(pivot, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
    "                cbar_kws={\"label\": metric})\n",
    "    plt.title(f\"{metric} - the impact of all perturbations\")\n",
    "    plt.xlabel(\"Method\")\n",
    "    plt.ylabel(\"Perturbation\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/heatmap_perturbations_{metric}.svg\", format=\"svg\")\n",
    "    plt.show()"
   ],
   "id": "64cbe8b1677fc101"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
